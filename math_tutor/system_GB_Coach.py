import os
import json
import re
from tkinter import Tk, filedialog
from datetime import datetime, time # type: ignore
from pathlib import Path # type: ignore
from typing import Optional, Dict, List, Union
import chromadb
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from langchain_groq import ChatGroq
import pandas as pd
from pydantic import BaseModel, Field
import mlflow
import streamlit as st
import sympy as sp
import matplotlib.pyplot as plt
from math_tutor.utils.file_processor import FileProcessor
from math_tutor.utils.long_term_memory import LongTermMemory

def setup_mlflow():
    mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', 'http://localhost:5000'))
    mlflow.set_experiment("Math_Tutoring_System")

# Initialisation
load_dotenv()

class StudentProfile(BaseModel):
    student_id: str
    name: Optional[str] = None
    level: int = 1
    current_objective: Optional[str] = None
    learning_history: List[Dict] = Field(default_factory=list)
    objectives_completed: List[str] = Field(default_factory=list)
    created_at: str = Field(default_factory=lambda: datetime.now().isoformat())
    last_session: Optional[str] = None

class Exercise(BaseModel):
    exercise: str = Field(description="Une question unique et pr√©cise adapt√©e √† l'objectif")
    solution: str = Field(description="Solution math√©matique d√©taill√©e et rigoureuse")
    hints: List[str] = Field(
        description="Indice principal pour guider l'√©l√®ve",
        default_factory=list
    )
    difficulty: str
    concept: str
class EvaluationResult(BaseModel):
    is_correct: bool = Field(..., description="Indique si la r√©ponse est correcte")
    error_type: Optional[str] = Field(None, description="Type d'erreur identifi√©") 
    feedback: str = Field(..., description="Feedback p√©dagogique d√©taill√© s l'erreur")
    detailed_explanation: str = Field(..., description="Explication math√©matique compl√®te")
    step_by_step_correction: str = Field(..., description="Correction √©tape par √©tape")
    recommendations: List[str] = Field(..., description="Recommandations personnalis√©es")

class CoachPersonal(BaseModel):
    motivation: str = Field(..., description="message motivant")
    strategy: str = Field(..., description="strat√©gie concr√®te") 
    tip: str = Field(..., description="astuce pratique")
    encouragement: List[str] = Field(..., description="phrase positive")

class LearningObjectives:
    def __init__(self, objectives_file="objectifs.json"):
        self.objectives_file = Path(objectives_file)
        self._load_objectives()

    def _load_objectives(self):
        try:
            with open(self.objectives_file, 'r', encoding='utf-8') as f:
                self.objectives = json.load(f)
                self.objectives_order = list(self.objectives.keys())
        except Exception as e:
            st.error(f"Erreur de chargement des objectifs: {str(e)}")
            self.objectives = {}
            self.objectives_order = []

class StudentManager:
    def __init__(self, data_dir="students_data", enable_memory: bool = True):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        self.client = chromadb.PersistentClient(path=str(self.data_dir / "memory_db"))

        self.long_term_memory = self._initialize_memory(enable_memory)


    
    def _initialize_memory(self, enable_memory):
        import shutil
        db_path = Path("students_data/memory_db")
        if db_path.exists():
            try:
                shutil.rmtree(db_path)
            except Exception as e:
                print(f"‚ö†Ô∏è Nettoyage base √©chou√©: {str(e)}")
        if not enable_memory:
            return None
            
        try:
            # R√©initialise la base si corrompue
            if hasattr(self, 'client'):
                try:
                    self.client.reset()
                except:
                    pass
                    
            from math_tutor.utils.long_term_memory import LongTermMemory
            memory = LongTermMemory("global_memory", client=self.client)
            
            if not memory.test_connection():
                raise ConnectionError("√âchec test connexion m√©moire")
                
            return memory
        except Exception as e:
            print(f"‚ö†Ô∏è Initialisation m√©moire √©chou√©e : {str(e)}")
            return None

    def create_student(self, name=None):
        student_id = datetime.now().strftime("%Y%m%d%H%M%S%f")[:16]
        profile = StudentProfile(
            student_id=student_id,
            name=name,
            last_session=datetime.now().isoformat()
        )
        self.save_student(profile)
        return profile

    def load_student(self, student_id):
        student_file = self.data_dir / f"{student_id}.json"
        if not student_file.exists():
            return None
        try:
            with open(student_file, 'r', encoding='utf-8') as f:
                return StudentProfile(**json.load(f))
        except Exception as e:
            st.error(f"Erreur de chargement: {str(e)}")
            return None

    def save_student(self, student):
        # Sauvegarde standard
        student_file = self.data_dir / f"{student.student_id}.json"
        try:
            with open(student_file, 'w', encoding='utf-8') as f:
                json.dump(student.model_dump(), f, indent=4)
            
            # Sauvegarde dans ChromaDB
            self._sync_to_long_term_memory(student)
        except Exception as e:
            st.error(f"Erreur de sauvegarde: {str(e)}")
    # def _safe_init_memory(self):
    #     """Initialisation avec fallback silencieux"""
    #     if not self.memory_enabled:
    #         return None
            
    #     try:
    #         # from math_tutor.utils.long_term_memory import LongTermMemory
    #         memory = LongTermMemory("global_memory")
    #         memory.client.heartbeat()  # Test de connexion
    #         return memory
    #     except Exception as e:
    #         st.warning(f"‚ö†Ô∏è Mode d√©grad√©: {str(e)}")
    #         return None


    def _sync_to_long_term_memory(self, student: StudentProfile) -> None:
        """Version ultra-robuste avec r√©essai automatique"""
        if not self.long_term_memory:
            if not hasattr(self, '_warned_memory'):
                print("‚ÑπÔ∏è M√©moire d√©sactiv√©e - mode d√©grad√© activ√©")
                self._warned_memory = True
            return

        metadata = {
            "type": "level_update",
            "student_id": student.student_id,
            "new_level": str(student.level),
            "timestamp": datetime.now().isoformat()
        }

        for attempt in range(3):  # 3 tentatives
            try:
                self.long_term_memory.upsert_memory(
                    content=f"Niveau {student.level} atteint par {student.name or 'anonyme'}",
                    metadata=metadata,
                    id=f"student_{student.student_id}_level_{student.level}"
                )
                return  # Succ√®s, on sort
            except Exception as e:
                if attempt == 2:  # Derni√®re tentative
                    self._handle_sync_error(e, student)
                else:
                    print(f"‚ö†Ô∏è Tentative {attempt + 1} √©chou√©e, nouvelle tentative...")
                    time.sleep(1)  # Pause avant r√©essai

    def _handle_sync_error(self, error: Exception, student: StudentProfile):
        """Gestion centralis√©e des erreurs avec journalisation"""
        error_msg = f"‚ùå Erreur synchronisation m√©moire: {str(error)}"
        print(error_msg)  # Log dans la console
        if 'st' in globals():  # Si Streamlit est disponible
            st.error(error_msg)
        
        # Sauvegarde d'urgence avec journalisation
        backup_dir = self.data_dir / "backups"
        try:
            backup_dir.mkdir(exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            backup_file = backup_dir / f"{timestamp}_{student.student_id}.json"
            
            with open(backup_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "student": student.model_dump(),
                    "error": str(error),
                    "timestamp": datetime.now().isoformat(),
                    "attempt": "memory_sync"
                }, f, indent=4)
                
            print(f"‚úÖ Sauvegarde secours cr√©√©e: {backup_file}")
        except Exception as backup_error:
            print(f"‚ùå √âchec sauvegarde secours: {str(backup_error)}")
class MathTutoringSystem:
    def __init__(self):
        self.llm = None
        try:
            self.llm = ChatGroq(
                api_key=os.getenv('GROQ_API_KEY'),
                model="llama-3.3-70b-versatile",  
                temperature=0.7
            )
            self.setup_mlflow()
        except Exception as e:
            st.error(f"Mode hors ligne activ√©: {str(e)}")
            self.llm = None 
        
        self.file_processor = FileProcessor()
        self.long_term_memory = None 

        # Initialiser les agents √† None d'abord
        self.exercise_creator = None
        self.evaluator = None
        self.personal_coach = None
        
        self.student_manager = StudentManager()
        self.learning_objectives = LearningObjectives()
        self.current_student = None
        
        # Configurer les agents puis MLflow
        self._setup_agents()

    def _setup_agents(self):
        if self.llm:

            self.exercise_creator = Agent(
                role="Cr√©ateur d'exercices",
                name="ExerciseCreator",
                goal="Cr√©er des exercices de math√©matiques parfaitement adapt√©s au niveau de l'√©tudiant",
                backstory=""" Expert p√©dagogique sp√©cialis√© dans l'enseignement des math√©matiques pour le baccalaur√©at marocain.
                             Ma√Ætrise parfaitement la progression p√©dagogique et sait cr√©er des exercices qui construisent 
                            graduellement la compr√©hension des concepts math√©matiques.""",
                llm=self.llm,
                verbose=False
            )
            self.evaluator = Agent(
                role="√âvaluateur Expert",
                name="AnswerEvaluator",
                goal="""Fournir des √©valuations pr√©cises et p√©dagogiques des r√©ponses math√©matiques.
                Identifier clairement les erreurs et fournir des explications d√©taill√©es.""",
                backstory="""Professeur agr√©g√© de math√©matiques avec 15 ans d'exp√©rience
                dans l'enseignement secondaire et sup√©rieur. Sp√©cialiste de la p√©dagogie diff√©renci√©e.""",
                llm=self.llm,
                verbose=False,
                max_iter=15,  # Pour des analyses plus approfondies
                memory=True 
            )
            self.personal_coach = Agent(
            role="Coach Personnel en Math√©matiques",
            name="PersonalMathCoach",
            goal="""Fournir un accompagnement personnalis√©, des encouragements 
            et des strat√©gies d'apprentissage adapt√©es √† chaque √©tudiant""",
            backstory="""Ancien professeur de math√©matiques devenu coach scolaire,
            sp√©cialis√© dans la motivation et la r√©solution des blocages psychologiques
            li√©s √† l'apprentissage des math√©matiques. Utilise des techniques de
            p√©dagogie positive et de renforcement des comp√©tences.""",
            llm=self.llm,
            verbose=False,
            memory=True,  
            max_iter=10   
        )
        if hasattr(self, 'mlflow_run'):
            try:
                mlflow.log_dict({
                    "exercise_creator": self.exercise_creator.model_dump(),
                    "evaluator": self.evaluator.model_dump(),
                    "personal_coach": self.personal_coach.model_dump()
                }, "agents_config.json")
            except Exception as e:
                st.error(f"Erreur lors du logging des agents: {str(e)}")

    def load_model_from_registry(model_name: str, stage: str = "Production"):
        return mlflow.pyfunc.load_model(f"models:/{model_name}/{stage}")
    
    
    
    def authenticate_student(self):
        """Version adapt√©e pour Streamlit"""
        if not hasattr(st.session_state, 'authenticated'):
            st.session_state.authenticated = False

        if st.session_state.authenticated:
            return True

        with st.form("auth_form"):
            choice = st.radio("Options", ["Cr√©er un profil", "Charger un profil"])
            name = st.text_input("Pr√©nom (optionnel)")
            student_id = st.text_input("ID √©tudiant") if choice == "Charger un profil" else None
            
            if st.form_submit_button("Valider"):
                if choice == "Cr√©er un profil":
                    self.current_student = self.student_manager.create_student(name)
                    st.success(f"Profil cr√©√© (ID: {self.current_student.student_id})")
                    st.session_state.authenticated = True
                else:
                    self.current_student = self.student_manager.load_student(student_id)
                    if self.current_student:
                        st.success(f"Bienvenue, {self.current_student.name or '√©tudiant'}!")
                        st.session_state.authenticated = True
                    else:
                        st.error("Profil non trouv√©")
        
        return st.session_state.authenticated
    
    def _load_initial_memories(self):
        """Charge les m√©moires initiales depuis le profil √©tudiant"""
        if not self.current_student:
            return
            
        # Ajouter les objectifs compl√©t√©s comme m√©moires
        for obj in self.current_student.objectives_completed:
            self.long_term_memory.add_memory(
                content=f"Objectif compl√©t√©: {obj}",
                metadata={"type": "achievement", "objective": obj}
            )
        
        # Ajouter l'historique d'apprentissage
        for item in self.current_student.learning_history:
            self.long_term_memory.add_memory(
                content=f"Exercice: {item['exercise']} - R√©ponse: {item['answer']}",
                metadata={
                    "type": "exercise",
                    "correct": str(item['evaluation']),
                    "timestamp": item['timestamp']
                }
            )
    
    def setup_mlflow(self):
        """Configure le suivi MLflow avec gestion des erreurs"""
        try:
            mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', 'http://localhost:5000'))
            mlflow.set_experiment("Math_Tutoring_System")
            self.mlflow_run = mlflow.start_run()
            
            # Enregistrez les param√®tres du mod√®le
            mlflow.log_params({
                "llm_model": "llama-3.3-70b",
                "temperature": 0.7,
                "max_iter": 15
            })
        except Exception as e:
            st.error(f"Avertissement MLflow: {str(e)}")
            self.mlflow_run = None


    def get_current_objective_info(self):
        """Retourne les infos de l'objectif actuel pour Streamlit"""
        if not self.current_student:
            return None
        
        objective = self.learning_objectives.objectives.get(self.current_student.current_objective or "", {})
        if not objective:
            return None
        
        level_info = objective["niveaux"].get(str(self.current_student.level), {})
        return {
            "description": objective.get("description", ""),
            "level_name": level_info.get("name", ""),
            "total_levels": len(objective["niveaux"]),
            "objectives": level_info.get("objectives", [])
        }

    def get_student_progress(self):
        """Retourne les statistiques de progression pour Streamlit"""
        if not self.current_student:
            return None
        
        return {
            "level": self.current_student.level,
            "completed": len(self.current_student.objectives_completed),
            "history": pd.DataFrame(self.current_student.learning_history)
        }

    def _generate_exercise(self) -> Optional[Exercise]:
        """G√©n√®re un exercice adapt√© √† l'objectif actuel avec meilleure gestion des erreurs"""
        with mlflow.start_span("exercise_generation"):
            # V√©rification de l'√©tudiant et de l'objectif
            if not self.current_student or not self.current_student.current_objective:
                st.error("Aucun √©tudiant ou objectif d√©fini")
                return None

            objective = self.learning_objectives.objectives.get(self.current_student.current_objective)
            if not objective:
                st.error(f"Objectif non trouv√©: {self.current_student.current_objective}")
                return None

            level_info = objective["niveaux"].get(str(self.current_student.level))
            if not level_info:
                st.error(f"Niveau non trouv√©: {self.current_student.level}")
                return None

            # Fallback de base
            default_exercise = Exercise(
                exercise=f"R√©soudre: {level_info['example_functions'][0]}",
                solution=f"Solution: {level_info['objectives'][0]}",
                hints=["Appliquez les m√©thodes appropri√©es"],
                difficulty=level_info['name'],
                concept=self.current_student.current_objective
            )

            if not self.llm:
                return default_exercise

            try:
                # Prompt plus d√©taill√©
                prompt = f"""
                Tu es un professeur de math√©matiques expert. Cr√©e un exercice avec:
                - Objectif: {objective['description']}
                - Niveau: {level_info['name']} 
                - Type: {self.current_student.current_objective}
                - Bas√© sur: {level_info['example_functions'][0]}

                L'exercice doit:
                1. √ätre clair et pr√©cis
                2. Avoir une solution d√©taill√©e
                3. Inclure 2-3 indices p√©dagogiques
                4. Correspondre au niveau de difficult√©
                """

                task = Task(
                    description=prompt,
                    agent=self.exercise_creator,
                    expected_output="Un objet Exercise complet avec exercise, solution, hints, difficulty et concept",
                    output_pydantic=Exercise
                )

                crew = Crew(
                    agents=[self.exercise_creator],
                    tasks=[task],
                    process=Process.sequential,
                    verbose=True 
                )

                result = crew.kickoff()
                # st.code("\nEXercice:", result['exercise'])
                # st.code("\nconcept:", result['concept'] )
                # st.code("\ndifficulty:", result['difficulty'])
                # st.code("\nhints:", "\n".join(result['hints']) )
                
                # Debug
                #console.print(f"[yellow]R√©sultat brut: {result}[/yellow]")
                if hasattr(self, 'mlflow_run') and self.mlflow_run:
                    try:
                        # R√©cup√©rer le niveau actuel comme m√©trique num√©rique
                        mlflow.log_metrics({
                            "student_level": self.current_student.level,
                            "hints_count": len(result.hints)
                        })
                        
                        # Enregistrer les d√©tails de la difficult√© comme param√®tre
                        mlflow.log_params({
                            "difficulty_name": result.difficulty,
                            "concept": result.concept
                        })
                        
                        mlflow.log_dict(result.model_dump(), "exercise_details.json")
                    except Exception as e:
                        st.error(f"Erreur MLflow: {str(e)}")


                return result

            except Exception as e:
                st.error(f"Erreur g√©n√©ration exercice: {str(e)}")
                return default_exercise
            
    def _evaluate_response(self, exercise: Exercise, answer: Union[str, Path]) -> EvaluationResult:
        """√âvaluation robuste avec gestion directe Pydantic"""
        with mlflow.start_span("answer_evaluation"):
            # Cas fichier (PDF/image)
            if isinstance(answer, (Path, str)) and Path(answer).exists():
                try:
                    extracted_text = self.file_processor.extract_text_from_file(str(answer))
                    if not extracted_text:
                        st.error("Aucun texte extrait du fichier")
                        return self._create_fallback_evaluation(exercise)
                    
                    # Utilisation directe avec Pydantic
                    return self._evaluate_prompt(exercise, extracted_text)
                    
                except Exception as e:
                    st.error(f"Erreur traitement fichier: {str(e)}")
                    return self._create_fallback_evaluation(exercise)
            
            # Cas texte
            return self._evaluate_prompt(exercise, str(answer))
        
    def _evaluate_prompt(self, exercise: Exercise, answer: str) -> EvaluationResult:
        """√âvalue une r√©ponse textuelle"""
        prompt = f"""
        CONTEXTE D'√âVALUATION
        ---------------------
        Exercice propos√© : {exercise.exercise}
        Solution de r√©f√©rence : {exercise.solution}
        R√©ponse de l'√©tudiant : {answer}

        CRIT√àRES D'ANALYSE D√âTAILL√âS
        ---------------------------
        1. Analyse du raisonnement:
        - Identifier toutes les √©tapes du raisonnement de l'√©tudiant
        - V√©rifier la coh√©rence logique entre les √©tapes
        - Examiner la pr√©sence des justifications n√©cessaires

        2. Classification des erreurs:
        Types d'erreurs √† consid√©rer:
        - Erreur conceptuelle (compr√©hension des notions)
        - Erreur de calcul (op√©rations math√©matiques)
        - Erreur de notation (√©criture math√©matique)
        - Erreur de m√©thode (choix de l'approche)
        - Erreur de logique (raisonnement)

        3. Recommandations p√©dagogiques:
        - Proposer des exercices de rem√©diation cibl√©s
        - Sugg√©rer des ressources sp√©cifiques
        - Indiquer les points √† revoir en priorit√©
        """

        task = Task(
            description=prompt,
            agent=self.evaluator,
            expected_output="Objet EvaluationResult complet: √âvaluation compl√®te avec validation, feedback et recommandations",
            output_pydantic=EvaluationResult
        )

        crew = Crew(
            agents=[self.evaluator], 
            tasks=[task], 
            process=Process.sequential,
            verbose=False
        )
        
        return crew.kickoff()

    
        
    def _create_fallback_evaluation(self, exercise: Exercise) -> EvaluationResult:
        """Cr√©e une √©valuation de secours"""
        return EvaluationResult(
            is_correct=False,
            error_type="system_error",
            feedback="Erreur lors de l'√©valuation",
            detailed_explanation=f"Explication: {exercise.concept}",
            step_by_step_correction=exercise.solution,
            recommendations=[
                "V√©rifiez votre r√©ponse manuellement",
                "Consultez la solution fournie",
                "Contactez votre enseignant"
            ]
        )

    def _provide_personalized_coaching(self, evaluation: EvaluationResult, exercise: Exercise) -> CoachPersonal:
        """Fournit un coaching personnalis√© avec sortie Pydantic directe"""
        # Fallback de base
        fallback_coaching = CoachPersonal(
            motivation="Continuez vos efforts!",
            strategy="Revoyez la solution fournie",
            tip="Relisez attentivement les √©tapes",
            encouragement=["Vous progressez √† chaque essai!"]
        )

        if not self.llm or not self.current_student:
            return fallback_coaching

        try:
            # Configuration directe de la t√¢che
            task = Task(
                description=self._build_coaching_prompt(exercise, evaluation),
                agent=self.personal_coach,
                expected_output="Retourne directement un objet CoachPersonal valide",
                output_pydantic=CoachPersonal  
            )

            # Ex√©cution simplifi√©e
            result = Crew(
                agents=[self.personal_coach],
                tasks=[task],
                process=Process.sequential
            ).kickoff()

            # Journalisation
            if hasattr(self, 'mlflow_run'):
                self._log_coaching_data(exercise, evaluation, result)
            
            return result

        except Exception as e:
            st.error(f"Erreur coaching: {str(e)}")
            return fallback_coaching

    def _build_coaching_prompt(self, exercise: Exercise, evaluation: EvaluationResult) -> str:
        """Prompt optimis√© pour une sortie Pydantic directe"""
        return f"""
        [INSTRUCTIONS STRICTES]
        - Analyser la performance de l'√©tudiant
        - G√©n√©rer UNIQUEMENT un objet CoachPersonal valide
        - Ne rien ajouter d'autre (pas de texte, markdown, etc.)

        [CONTEXTE]
        Exercice: {exercise.exercise}
        R√©ussite: {'Correct' if evaluation.is_correct else 'Incorrect'}
        Erreur: {evaluation.error_type or 'Aucune'}

        [FORMAT DE SORTIE]
        {CoachPersonal}
        """

    def _log_coaching_data(self, exercise: Exercise, evaluation: EvaluationResult, coaching: CoachPersonal):
        """Journalisation des donn√©es de coaching"""
        try:
            mlflow.log_metrics({
                "coaching_strategy_len": len(coaching.strategy),
                "encouragement_count": len(coaching.encouragement)
            })
            
            mlflow.log_dict({
                "exercise": exercise.model_dump(),
                "evaluation": evaluation.model_dump(),
                "coaching": coaching.model_dump()
            }, "coaching_session.json")
        except Exception as e:
            st.warning("‚ö†Ô∏è Erreur journalisation: {str(e)}")

    
    def start_learning_session(self):
        if not self.authenticate_student():
            return

        if 'current_exercise' not in st.session_state:
            st.session_state.current_exercise = None
            st.session_state.attempts = 0

        # Afficher les infos √©tudiant
        st.header(f"Bienvenue, {self.current_student.name or '√âtudiant'}!")

        st.header(
            f"Bienvenue, {self.current_student.name or '√©tudiant'}!",
            divider="bold green"
        )

        while True:  # Boucle principale de session
            # Afficher les infos du niveau
            objective = self.learning_objectives.objectives.get(self.current_student.current_objective or "")
            if not objective:
                st.error("‚ùå Objectif non trouv√©")
                break
                
            level_info = objective["niveaux"].get(str(self.current_student.level))
            if not level_info:
                st.error("‚ùå Niveau non trouv√©")
                break

            st.header(
                f"üéØ {objective['description']}\n"
                f"üìä Niveau {self.current_student.level}: {level_info['name']}\n"
                f"üìù Objectifs: {' | '.join(level_info['objectives'])}",
                divider="blue"
            )

            # G√©n√©rer le premier exercice
            exercise = self._generate_exercise()
            if not exercise:
                st.error("‚ùå Impossible de g√©n√©rer un exercice")
                break

            while True:  # Boucle pour g√©rer un exercice (original ou similaire)
                
                attempts = 0
                max_attempts = 2
                last_evaluation = None
                exercise_completed = False

                while attempts < max_attempts:  # Boucle des tentatives
                    st.header(
                        f"üìù Exercice (tentative {attempts + 1}/{max_attempts}):\n{exercise.exercise}",
                        divider="green"
                    )
                    input_mode = st.text_input("‚úèÔ∏è Comment souhaitez-vous r√©pondre ?", choices=["texte", "fichier", "hint", "quit"])

                    if input_mode.lower() == "quit":
                        return
                    elif input_mode.lower() == "hint":
                        hints = "\n".join(f"‚Ä¢ {hint}" for hint in exercise.hints)
                        st.info(f"\nüí°[bold]Indice:[/bold]\n{hints}")
                        input_mode = st.text_input("‚úèÔ∏è Apr√®s l'indice, souhaitez-vous r√©pondre par 'texte' ou 'fichier'?", choices=["texte", "fichier"])
                        attempts = max(0, attempts - 1) if attempts > 0 else 0

                    if input_mode == "texte":
                        answer = st.text_input("‚úèÔ∏è Entrez votre r√©ponse")
                    elif input_mode == "fichier":
                        file_path = self.choisir_fichier()
                        if file_path and Path(file_path).exists():
                            answer = file_path
                        else:
                            st.error("‚ùå Fichier non valide ou non s√©lectionn√©")
                            continue
        
                    else:
                        st.error("‚ùå Mode de r√©ponse inconnu")
                        continue


                    try:
                        evaluation = self._evaluate_response(exercise, answer)
                        self._display_evaluation(evaluation, exercise)
                        last_evaluation = evaluation
                        
                        self.current_student.learning_history.append({
                            "exercise": exercise.exercise,
                            "answer": answer,
                            "evaluation": evaluation.is_correct,
                            "timestamp": datetime.now().isoformat(),
                            "attempt": attempts + 1
                        })

                        if evaluation.is_correct:
                            exercise_completed = True
                            break

                    except Exception as e:
                        st.error(f"Erreur critique: {str(e)}")
                        evaluation = self._create_fallback_evaluation(exercise)
                        self._display_evaluation(evaluation,exercise)
                        last_evaluation = evaluation
                    
                    attempts += 1

                # Apr√®s les tentatives
                if exercise_completed:
                    # Mise √† jour progression apr√®s exercice r√©ussi
                    max_level = len(objective["niveaux"])
                    if self.current_student.level < max_level:
                        self.current_student.level += 1
                    else:
                        next_obj = self.learning_objectives.objectives_order.index(self.current_student.current_objective) + 1
                        if next_obj < len(self.learning_objectives.objectives_order):
                            self.current_student.objectives_completed.append(self.current_student.current_objective)
                            self.current_student.current_objective = self.learning_objectives.objectives_order[next_obj]
                            self.current_student.level = 1
                    
                    self.student_manager.save_student(self.current_student)
                    break  # Sort de la boucle d'exercice pour passer au suivant
                else:
                    choice  = st.text_input(
                        "\nVoulez-vous un exercice similaire pour vous entra√Æner?",
                        choices=["oui", "non"],
                        default="oui"
                    )
                    if choice == "oui":
                        exercise = self._generate_similar_exercise(exercise)
                        continue  # Recommence avec nouvel exercice similaire
                    else:
                        break  # Sort de la boucle d'exercice

            # Demander si continuer avec nouvel objectif
            if not st.text_input("\nContinuer avec un nouvel exercice?", choices=["oui", "non"], default="oui"):
                break

        # Rapport final
        self._display_progress_report()
        st.success("\nüéâ Session termin√©e!")
    

    def choisir_fichier(self):
        """Version Streamlit"""
        uploaded_file = st.file_uploader("T√©l√©verser un fichier", 
                                    type=["png", "jpg", "jpeg", "pdf"])
        if uploaded_file:
            # Sauvegarde temporaire du fichier
            file_path = os.path.join("temp_uploads", uploaded_file.name)
            os.makedirs("temp_uploads", exist_ok=True)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            return file_path
        return None




    def _generate_similar_exercise(self, original_exercise: Exercise) -> Exercise:
        """G√©n√®re un exercice similaire au pr√©c√©dent (m√™me concept et difficult√©)"""
        if not self.llm:
            # Fallback simple - ajoute une variation √† l'exercice original
            modified_exercise = original_exercise.exercise.replace("=", "+ 1 =") if "=" in original_exercise.exercise else original_exercise.exercise + " (variation)"
            return Exercise(
                exercise=modified_exercise,
                solution=f"Solution similaire √†: {original_exercise.solution}",
                hints=original_exercise.hints,
                difficulty=original_exercise.difficulty,
                concept=original_exercise.concept
            )

        try:
            task = Task(
                description=f"""
                Tu es un professeur de math√©matiques expert.
                G√©n√®re un NOUVEL exercice SIMILAIRE mais DIFF√âRENT √† l'exercice suivant, 
                avec la M√äME difficult√© et portant sur le M√äME concept math√©matique.

                CONTEXTE:
                - Exercice original: {original_exercise.exercise}
                - Concept: {original_exercise.concept}
                - Difficult√©: {original_exercise.difficulty}
                - Solution originale: {original_exercise.solution}

                EXIGENCES:
                1. L'exercice doit tester les m√™mes comp√©tences mais avec des valeurs/nombres diff√©rents
                2. Doit √™tre du m√™me niveau de difficult√©
                3. Doit inclure une solution compl√®te
                4. Doit fournir des indices p√©dagogiques
                5. Doit √™tre clair et pr√©cis
                """,
                expected_output="Un objet Exercise complet avec les champs: exercise, solution, hints, difficulty, concept",
                agent=self.exercise_creator,
                output_pydantic=Exercise
            )

            crew = Crew(
                agents=[self.exercise_creator], 
                tasks=[task],
                process=Process.sequential,
                verbose=False 
            )
            
            result = crew.kickoff()
            # print("\nEXercice:", result['exercise'])
            # print("\nconcept:", result['concept'] )
            # print("\ndifficulty:", result['difficulty'])
            # print("\nhints:", "\n".join(result['hints']) )
            return result
            
        except Exception as e:
            st.error(f"Erreur lors de la g√©n√©ration d'exercice similaire: {str(e)}")
            # Fallback en cas d'erreur
            return self._generate_exercise()
        
    def monitor_student_progress(self):
        """Surveille la progression des √©tudiants"""
        from evidently.report import Report
        from evidently.metrics import (
            ColumnDriftMetric,
            DatasetDriftMetric,
            DatasetMissingValuesMetric
        )
        
        if not self.current_student or not self.current_student.learning_history:
            return

        # Convertir l'historique en DataFrame
        df = pd.DataFrame(self.current_student.learning_history)
        
        # Configurer le rapport
        report = Report(metrics=[
            ColumnDriftMetric(column_name="is_correct"),
            DatasetDriftMetric(),
            DatasetMissingValuesMetric()
        ])
        
        # G√©n√©rer le rapport
        report.run(
            reference_data=df.iloc[:len(df)//2],  # Premi√®re moiti√© comme r√©f√©rence
            current_data=df.iloc[len(df)//2:],    # Deuxi√®me moiti√© comme donn√©es courantes
        )
        
        # Sauvegarder le rapport
        if hasattr(self, 'mlflow_run') and self.mlflow_run:
            mlflow.log_dict(report.json(), "monitoring_report.json")
        
if __name__ == "__main__":
    # try:
    #     system = MathTutoringSystem()
    #     system.start_learning_session()
    # except Exception as e:
    # finally:
    #     st.code("Merci d'avoir utilis√© notre syst√®me!")
    try:
        mlflow.log_metric("test", 1)
    except Exception as e:
        chromadb.logger.error(f"Erreur MLflow: {str(e)}")
    
import os
import json
import re
from datetime import datetime # type: ignore
from pathlib import Path # type: ignore
from typing import Optional, Dict, List
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from langchain_groq import ChatGroq
from pydantic import BaseModel, Field
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Prompt
import mlflow

def setup_mlflow():
    mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', 'http://localhost:5000'))
    mlflow.set_experiment("Math_Tutoring_System")

# Initialisation
load_dotenv()
console = Console()

class StudentProfile(BaseModel):
    student_id: str
    name: Optional[str] = None
    level: int = 1
    current_objective: Optional[str] = None
    learning_history: List[Dict] = Field(default_factory=list)
    objectives_completed: List[str] = Field(default_factory=list)
    created_at: str = Field(default_factory=lambda: datetime.now().isoformat())
    last_session: Optional[str] = None

class Exercise(BaseModel):
    exercise: str = Field(description="Une question unique et pr√©cise adapt√©e √† l'objectif")
    solution: str = Field(description="Solution math√©matique d√©taill√©e et rigoureuse")
    hints: List[str] = Field(
        description="Indice principal pour guider l'√©l√®ve",
        default_factory=list
    )
    difficulty: str
    concept: str
class EvaluationResult(BaseModel):
    is_correct: bool = Field(..., description="Indique si la r√©ponse est correcte")
    error_type: Optional[str] = Field(None, description="Type d'erreur identifi√©") 
    feedback: str = Field(..., description="Feedback p√©dagogique d√©taill√© s l'erreur")
    detailed_explanation: str = Field(..., description="Explication math√©matique compl√®te")
    step_by_step_correction: str = Field(..., description="Correction √©tape par √©tape")
    recommendations: List[str] = Field(..., description="Recommandations personnalis√©es")

class CoachPersonal(BaseModel):
    motivation: str = Field(..., description="message motivant")
    strategy: str = Field(..., description="strat√©gie concr√®te") 
    tip: str = Field(..., description="astuce pratique")
    encouragement: List[str] = Field(..., description="phrase positive")

class LearningObjectives:
    def __init__(self, objectives_file="objectifs.json"):
        self.objectives_file = Path(objectives_file)
        self._load_objectives()

    def _load_objectives(self):
        try:
            with open(self.objectives_file, 'r', encoding='utf-8') as f:
                self.objectives = json.load(f)
                self.objectives_order = list(self.objectives.keys())
        except Exception as e:
            console.print(f"[red]Erreur de chargement des objectifs: {str(e)}[/red]")
            self.objectives = {}
            self.objectives_order = []

class StudentManager:
    def __init__(self, data_dir="students_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)

    def create_student(self, name=None):
        student_id = datetime.now().strftime("%Y%m%d%H%M%S%f")[:16]
        profile = StudentProfile(
            student_id=student_id,
            name=name,
            last_session=datetime.now().isoformat()
        )
        self.save_student(profile)
        return profile

    def load_student(self, student_id):
        student_file = self.data_dir / f"{student_id}.json"
        if not student_file.exists():
            return None
        try:
            with open(student_file, 'r', encoding='utf-8') as f:
                return StudentProfile(**json.load(f))
        except Exception as e:
            console.print(f"[red]Erreur de chargement: {str(e)}[/red]")
            return None

    def save_student(self, student):
        student_file = self.data_dir / f"{student.student_id}.json"
        try:
            with open(student_file, 'w', encoding='utf-8') as f:
                json.dump(student.dict(), f, indent=4)
        except Exception as e:
            console.print(f"[red]Erreur de sauvegarde: {str(e)}[/red]")

class MathTutoringSystem:
    def __init__(self):
        self.llm = None
        try:
            self.llm = ChatGroq(
                api_key=os.getenv('GROQ_API_KEY'),
                model="groq/llama-3.3-70b-versatile",  
                temperature=0.7
            )
            self.setup_mlflow()
        except Exception as e:
            console.print(f"[yellow]Mode hors ligne activ√©: {str(e)}[/yellow]")
            self.llm = None 
        
        # Initialiser les agents √† None d'abord
        self.exercise_creator = None
        self.evaluator = None
        self.personal_coach = None
        
        self.student_manager = StudentManager()
        self.learning_objectives = LearningObjectives()
        self.current_student = None
        
        # Configurer les agents puis MLflow
        self._setup_agents()

    def _setup_agents(self):
        if self.llm:

            self.exercise_creator = Agent(
                role="Cr√©ateur d'exercices",
                name="ExerciseCreator",
                goal="Cr√©er des exercices de math√©matiques parfaitement adapt√©s au niveau de l'√©tudiant",
                backstory=""" Expert p√©dagogique sp√©cialis√© dans l'enseignement des math√©matiques pour le baccalaur√©at marocain.
                             Ma√Ætrise parfaitement la progression p√©dagogique et sait cr√©er des exercices qui construisent 
                            graduellement la compr√©hension des concepts math√©matiques.""",
                llm=self.llm,
                verbose=False
            )
            self.evaluator = Agent(
                role="√âvaluateur Expert",
                name="AnswerEvaluator",
                goal="""Fournir des √©valuations pr√©cises et p√©dagogiques des r√©ponses math√©matiques.
                Identifier clairement les erreurs et fournir des explications d√©taill√©es.""",
                backstory="""Professeur agr√©g√© de math√©matiques avec 15 ans d'exp√©rience
                dans l'enseignement secondaire et sup√©rieur. Sp√©cialiste de la p√©dagogie diff√©renci√©e.""",
                llm=self.llm,
                verbose=False,
                max_iter=15,  # Pour des analyses plus approfondies
                memory=True 
            )
            self.personal_coach = Agent(
            role="Coach Personnel en Math√©matiques",
            name="PersonalMathCoach",
            goal="""Fournir un accompagnement personnalis√©, des encouragements 
            et des strat√©gies d'apprentissage adapt√©es √† chaque √©tudiant""",
            backstory="""Ancien professeur de math√©matiques devenu coach scolaire,
            sp√©cialis√© dans la motivation et la r√©solution des blocages psychologiques
            li√©s √† l'apprentissage des math√©matiques. Utilise des techniques de
            p√©dagogie positive et de renforcement des comp√©tences.""",
            llm=self.llm,
            verbose=False,
            memory=True,  
            max_iter=10   
        )
        if hasattr(self, 'mlflow_run'):
            try:
                mlflow.log_dict({
                    "exercise_creator": self.exercise_creator.model_dump(),
                    "evaluator": self.evaluator.model_dump(),
                    "personal_coach": self.personal_coach.model_dump()
                }, "agents_config.json")
            except Exception as e:
                console.print(f"[yellow]Erreur lors du logging des agents: {str(e)}[/yellow]")

    def load_model_from_registry(model_name: str, stage: str = "Production"):
        return mlflow.pyfunc.load_model(f"models:/{model_name}/{stage}")
    
    def authenticate_student(self):
        console.print(Panel.fit("üîê Syst√®me de Tutorat Math√©matique", style="bold blue"))
        
        choice = Prompt.ask(
            "1. Cr√©er un profil\n2. Charger un profil",
            choices=["1", "2"],
            default="1"
        )
        
        if choice == "1":
            name = Prompt.ask("Pr√©nom (optionnel)")
            self.current_student = self.student_manager.create_student(name)
            console.print(f"[green]‚úÖ Profil cr√©√© (ID: {self.current_student.student_id})[/green]")
            
            if self.learning_objectives.objectives_order:
                self.current_student.current_objective = self.learning_objectives.objectives_order[0]
                self.student_manager.save_student(self.current_student)
            return True
        else:
            student_id = Prompt.ask("ID √©tudiant")
            self.current_student = self.student_manager.load_student(student_id)
            if not self.current_student:
                console.print("[red]‚ùå Profil non trouv√©[/red]")
                return False
            console.print(f"[green]‚úÖ Bienvenue, {self.current_student.name or '√©tudiant'}![/green]")
            return True
    
    def setup_mlflow(self):
        """Configure le suivi MLflow avec gestion des erreurs"""
        try:
            mlflow.set_tracking_uri(os.getenv('MLFLOW_TRACKING_URI', 'http://localhost:5000'))
            mlflow.set_experiment("Math_Tutoring_System")
            self.mlflow_run = mlflow.start_run()
            
            # Enregistrez les param√®tres du mod√®le
            mlflow.log_params({
                "llm_model": "llama-3.3-70b",
                "temperature": 0.7,
                "max_iter": 15
            })
        except Exception as e:
            console.print(f"[yellow]Avertissement MLflow: {str(e)}[/yellow]")
            self.mlflow_run = None

    def _generate_exercise(self) -> Optional[Exercise]:
        """G√©n√®re un exercice adapt√© √† l'objectif actuel avec meilleure gestion des erreurs"""
        with mlflow.start_span("exercise_generation"):
            # V√©rification de l'√©tudiant et de l'objectif
            if not self.current_student or not self.current_student.current_objective:
                console.print("[red]Aucun √©tudiant ou objectif d√©fini[/red]")
                return None

            objective = self.learning_objectives.objectives.get(self.current_student.current_objective)
            if not objective:
                console.print(f"[red]Objectif non trouv√©: {self.current_student.current_objective}[/red]")
                return None

            level_info = objective["niveaux"].get(str(self.current_student.level))
            if not level_info:
                console.print(f"[red]Niveau non trouv√©: {self.current_student.level}[/red]")
                return None

            # Fallback de base
            default_exercise = Exercise(
                exercise=f"R√©soudre: {level_info['example_functions'][0]}",
                solution=f"Solution: {level_info['objectives'][0]}",
                hints=["Appliquez les m√©thodes appropri√©es"],
                difficulty=level_info['name'],
                concept=self.current_student.current_objective
            )

            if not self.llm:
                return default_exercise

            try:
                # Prompt plus d√©taill√©
                prompt = f"""
                Tu es un professeur de math√©matiques expert. Cr√©e un exercice avec:
                - Objectif: {objective['description']}
                - Niveau: {level_info['name']} 
                - Type: {self.current_student.current_objective}
                - Bas√© sur: {level_info['example_functions'][0]}

                L'exercice doit:
                1. √ätre clair et pr√©cis
                2. Avoir une solution d√©taill√©e
                3. Inclure 2-3 indices p√©dagogiques
                4. Correspondre au niveau de difficult√©
                """

                task = Task(
                    description=prompt,
                    agent=self.exercise_creator,
                    expected_output="Un objet Exercise complet avec exercise, solution, hints, difficulty et concept",
                    output_pydantic=Exercise
                )

                crew = Crew(
                    agents=[self.exercise_creator],
                    tasks=[task],
                    process=Process.sequential,
                    verbose=True 
                )

                result = crew.kickoff()
                print("\nEXercice:", result['exercise'])
                print("\nconcept:", result['concept'] )
                print("\ndifficulty:", result['difficulty'])
                print("\nhints:", "\n".join(result['hints']) )
                
                # Debug
                #console.print(f"[yellow]R√©sultat brut: {result}[/yellow]")
                if hasattr(self, 'mlflow_run') and self.mlflow_run:
                    try:
                        # R√©cup√©rer le niveau actuel comme m√©trique num√©rique
                        mlflow.log_metrics({
                            "student_level": self.current_student.level,
                            "hints_count": len(result['hints'])
                        })
                        
                        # Enregistrer les d√©tails de la difficult√© comme param√®tre
                        mlflow.log_params({
                            "difficulty_name": result['difficulty'],
                            "concept": result['concept']
                        })
                        
                        mlflow.log_dict(result.dict(), "exercise_details.json")
                    except Exception as e:
                        console.print(f"[yellow]Erreur MLflow: {str(e)}[/yellow]")


                return result

            except Exception as e:
                console.print(f"[red]Erreur g√©n√©ration exercice: {str(e)}[/red]")
                return default_exercise
            
    def _evaluate_response(self, exercise: Exercise, answer: str) -> EvaluationResult:
        """√âvaluation ultra-robuste avec gestion d'erreur compl√®te"""
        with mlflow.start_span("answer_evaluation"):
            if not self.llm:
                return self._create_fallback_evaluation(exercise)

            try:
                prompt = f"""
                    CONTEXTE D'√âVALUATION
                    ---------------------
                    Exercice propos√© : {exercise['exercise']}
                    Solution de r√©f√©rence : {exercise['solution']}
                    R√©ponse de l'√©tudiant : {answer}

                    CRIT√àRES D'ANALYSE D√âTAILL√âS
                    ---------------------------
                    1. Analyse du raisonnement:
                    - Identifier toutes les √©tapes du raisonnement de l'√©tudiant
                    - V√©rifier la coh√©rence logique entre les √©tapes
                    - Examiner la pr√©sence des justifications n√©cessaires

                    2. Classification des erreurs avec justification
                    Types d'erreurs √† consid√©rer:
                    - Erreur conceptuelle (compr√©hension des notions)
                    - Erreur de calcul (op√©rations math√©matiques)
                    - Erreur de notation (√©criture math√©matique)
                    - Erreur de m√©thode (choix de l'approche)
                    - Erreur de logique (raisonnement)

                    3. V√©rification de la solution:
                    - Comparer la r√©ponse finale avec la solution attendue
                    - V√©rifier si le r√©sultat est math√©matiquement correct
                    - √âvaluer si la forme de la r√©ponse est appropri√©e

                    4. Recommandations p√©dagogiques:
                    - Proposer des exercices de rem√©diation cibl√©s
                    - Sugg√©rer des ressources sp√©cifiques
                    - Indiquer les points √† revoir en priorit√©
                    """

                task = Task(
                    description=prompt,
                    agent=self.evaluator,
                    expected_output="√âvaluation de l'√©tudiant avec is_correct, feedback d√©taill√©, type d'erreur et recommendations",
                    output_pydantic=EvaluationResult
                )

                crew = Crew(agents=[self.evaluator], tasks=[task], process=Process.sequential)
                result = crew.kickoff()
                # print("R√©ponse correcte:", result['is_correct'])
                # print("Type d'erreur:", result['error_type'] )
                # print("\nFeedback d√©taill√©:", result['feedback'])
                # print("\nRecommandations:", "\n".join(result['recommendations']) )
                # print("\nstep_by_step_correction:" , result['step_by_step_correction'] )
                mlflow.log_metrics({
                    "is_correct": int(result['is_correct'])
                })
                if result['error_type']:
                    mlflow.log_params({
                        "error_type": result['error_type']
                    })
                return result
                
            except Exception as e:
                console.print(f"[red]Erreur d'√©valuation: {str(e)}[/red]")
                return self._create_fallback_evaluation(exercise)
                
    def _create_fallback_evaluation(self, exercise: Exercise) -> EvaluationResult:
        """Cr√©e une √©valuation de secours"""
        return EvaluationResult(
            is_correct=False,
            error_type="system_error",
            feedback="Erreur lors de l'√©valuation",
            detailed_explanation=f"Explication: {exercise['concept']}",
            step_by_step_correction=exercise['solution'],
            recommendations=[
                "V√©rifiez votre r√©ponse manuellement",
                "Consultez la solution fournie",
                "Contactez votre enseignant"
            ]
        )

    def _provide_personalized_coaching(self, evaluation: EvaluationResult, exercise: Exercise) -> CoachPersonal:
        """Fournit un accompagnement personnalis√© bas√© sur l'√©valuation"""
        if not self.llm or not self.current_student:
            return {
                "motivation": "Continuez vos efforts!",
                "learning_strategy": "Revoyez la solution fournie",
                "encouragement": "Vous progressez √† chaque essai!"
            }

        try:
            task = Task(
                description=f"""
                En tant que coach personnel, analysez cette situation:
                
                √âTUDIANT:
                - Nom/Niveau: {self.current_student.name or "Anonyme"} (niveau {self.current_student.level})
                - Objectif: {self.current_student.current_objective}
                
                PERFORMANCE:
                - Exercice: {exercise['exercise']}
                - R√©ussite: {'Oui' if evaluation['is_correct'] else 'Non'}
                - Type d'erreur: {evaluation['error_type']}
                
                Votre mission:
                1. Formulez un message de motivation PERSONNALIS√â
                2. Proposez une strat√©gie d'apprentissage adapt√©e
                3. Donnez un conseil pour surmonter les difficult√©s
                4. Adaptez votre ton √† la performance de l'√©tudiant

                """,
                agent=self.personal_coach,
                expected_output="coaching l'√©tudiant avec une motivation, strat√©gie, des astuces pratiques,phrase positive ",
                output_pydantic=CoachPersonal,
            )

            crew = Crew(
                agents=[self.personal_coach],
                tasks=[task],
                process=Process.sequential,
                verbose=False
            )
            
            return crew.kickoff()

        except Exception as e:
            console.print(f"[red]Erreur coaching: {str(e)}[/red]")
            return {
                "motivation": "Vos efforts comptent!",
                "learning_strategy": "Analysez vos erreurs attentivement",
                "encouragement": "Chaque erreur est une occasion d'apprendre"
            }
    
    def _display_progress_report(self):
        """Affiche un rapport de progression d√©taill√©"""
        if not self.current_student:
            return

        console.print(Panel.fit("üìä Rapport de Progression", style="bold blue"))
        
        # Objectif actuel
        objective = self.learning_objectives.objectives.get(self.current_student.current_objective or "", {})
        console.print(f"üéØ Objectif actuel: {objective.get('description', 'Aucun')}")
        console.print(f"üìà Niveau actuel: {self.current_student.level}")
        
        # Objectifs compl√©t√©s
        if self.current_student.objectives_completed:
            console.print("\n‚úÖ Objectifs compl√©t√©s:")
            for obj in self.current_student.objectives_completed:
                console.print(f"- {obj}")
        else:
            console.print("\nüìå Aucun objectif compl√©t√© pour le moment")

        # Statistiques
        total_attempts = len(self.current_student.learning_history)
        correct_answers = sum(1 for x in self.current_student.learning_history if x.get('is_correct', False))
        console.print(f"\nüìù Tentatives: {total_attempts} | ‚úÖ Correctes: {correct_answers}")
        correct_answers = sum(1 for x in self.current_student.learning_history if x.get('is_correct', False))
        accuracy = correct_answers / len(self.current_student.learning_history) if self.current_student.learning_history else 0
        
        mlflow.log_metrics({
            "student_level": self.current_student.level,
            "completion_rate": len(self.current_student.objectives_completed),
            "accuracy_rate": accuracy
        })

    def _display_evaluation(self, evaluation: EvaluationResult, exercise: Exercise ):
        """Affichage complet et structur√© de l'√©valuation"""
        console.print("\n" + "="*60)
        console.print(Panel.fit("üìã R√âSULTAT DE L'√âVALUATION", style="bold blue"))

        # Section R√©sultat Principal
        if evaluation['is_correct']:
            console.print(Panel.fit(
                "‚úÖ [bold green]R√âPONSE CORRECTE[/bold green]",
                style="green"
            ))
        else:
            error_display = evaluation['error_type']
            console.print(Panel.fit(
                f"‚ùå [bold red]R√âPONSE INCORRECTE[/bold red] ([yellow]{error_display}[/yellow])",
                style="red"
            ))

        # Section Feedback
        if evaluation['feedback']:
            console.print(Panel.fit(
                f"[bold]üìù Feedback:[/bold]\n{evaluation['feedback']}",
                border_style="blue"
            ))

        # Section Explication
        if evaluation["detailed_explanation"]:
            console.print(Panel.fit(
                f"[bold]üîç Explication D√©taill√©e:[/bold]\n{evaluation['detailed_explanation']}",
                border_style="blue"
            ))

        # Section Correction
        if evaluation['step_by_step_correction']:
            console.print(Panel.fit(
                f"[bold]‚úèÔ∏è Correction √âtape par √âtape:[/bold]\n{evaluation['step_by_step_correction']}",
                border_style="green"
            ))

        # Section Recommandations
        if evaluation['recommendations']:
            recs = "\n".join(f"‚Ä¢ {rec}" for rec in evaluation['recommendations'])
            console.print(Panel.fit(
                f"[bold]üí° Recommandations:[/bold]\n{recs}",
                border_style="yellow"
            ))
        coaching = self._provide_personalized_coaching(evaluation, exercise)
        #tips = "\n".join(f"‚Ä¢ {tip}" for tip in coaching['tip'])
        console.print(Panel.fit(
            f"[bold]üß† Coaching Personnalis√©:[/bold]\n"
            f"üí™ [bold]Motivation:[/bold] {coaching['motivation']}\n"
            f"üìö [bold]Strat√©gie:[/bold] {coaching['strategy']}\n"
            f"üí° [bold]Astuce:[/bold]{coaching['tip']}\n"
            f"‚ú® [bold]Encouragement:[/bold] {coaching['encouragement']}",
            border_style="magenta"
        ))

        console.print("="*60 + "\n")

    


    def start_learning_session(self):
        if not self.authenticate_student():
            return

        console.print(Panel.fit(
            f"Bienvenue, {self.current_student.name or '√©tudiant'}!",
            style="bold green"
        ))

        while True:  # Boucle principale de session
            # Afficher les infos du niveau
            objective = self.learning_objectives.objectives.get(self.current_student.current_objective or "")
            if not objective:
                console.print("[red]‚ùå Objectif non trouv√©[/red]")
                break
                
            level_info = objective["niveaux"].get(str(self.current_student.level))
            if not level_info:
                console.print("[red]‚ùå Niveau non trouv√©[/red]")
                break

            console.print(Panel.fit(
                f"üéØ {objective['description']}\n"
                f"üìä Niveau {self.current_student.level}: {level_info['name']}\n"
                f"üìù Objectifs: {' | '.join(level_info['objectives'])}",
                style="blue"
            ))

            # G√©n√©rer le premier exercice
            exercise = self._generate_exercise()
            if not exercise:
                console.print("[red]‚ùå Impossible de g√©n√©rer un exercice[/red]")
                break

            while True:  # Boucle pour g√©rer un exercice (original ou similaire)
                
                attempts = 0
                max_attempts = 2
                last_evaluation = None
                exercise_completed = False

                while attempts < max_attempts:  # Boucle des tentatives
                    console.print(Panel.fit(
                        f"üìù Exercice (tentative {attempts + 1}/{max_attempts}):\n{exercise['exercise']}",
                        style="green"
                    ))

                    answer = Prompt.ask("‚úèÔ∏è Votre r√©ponse (ou 'hint' pour indice, 'quit' pour quitter)")
                    if answer.lower() == 'quit':
                        return
                    elif answer.lower() == 'hint':
                        hints = "\n".join(f"‚Ä¢ {hint}" for hint in exercise['hints'])
                        console.print(f"\nüí°[bold]Indice:[/bold]\n{hints}")
                        answer = Prompt.ask("‚úèÔ∏è Votre r√©ponse apr√®s l'indice")

                    try:
                        evaluation = self._evaluate_response(exercise, answer)
                        self._display_evaluation(evaluation, exercise)
                        last_evaluation = evaluation
                        
                        self.current_student.learning_history.append({
                            "exercise": exercise['exercise'],
                            "answer": answer,
                            "evaluation": evaluation['is_correct'],
                            "timestamp": datetime.now().isoformat(),
                            "attempt": attempts + 1
                        })

                        if evaluation['is_correct']:
                            exercise_completed = True
                            break

                    except Exception as e:
                        console.print(f"[red]Erreur critique: {str(e)}[/red]")
                        evaluation = self._create_fallback_evaluation(exercise)
                        self._display_evaluation(evaluation,exercise)
                        last_evaluation = evaluation
                    
                    attempts += 1

                # Apr√®s les tentatives
                if exercise_completed:
                    # Mise √† jour progression apr√®s exercice r√©ussi
                    max_level = len(objective["niveaux"])
                    if self.current_student.level < max_level:
                        self.current_student.level += 1
                    else:
                        next_obj = self.learning_objectives.objectives_order.index(self.current_student.current_objective) + 1
                        if next_obj < len(self.learning_objectives.objectives_order):
                            self.current_student.objectives_completed.append(self.current_student.current_objective)
                            self.current_student.current_objective = self.learning_objectives.objectives_order[next_obj]
                            self.current_student.level = 1
                    
                    self.student_manager.save_student(self.current_student)
                    break  # Sort de la boucle d'exercice pour passer au suivant
                else:
                    choice = Prompt.ask(
                        "\nVoulez-vous un exercice similaire pour vous entra√Æner?",
                        choices=["oui", "non"],
                        default="oui"
                    )
                    if choice == "oui":
                        exercise = self._generate_similar_exercise(exercise)
                        continue  # Recommence avec nouvel exercice similaire
                    else:
                        break  # Sort de la boucle d'exercice

            # Demander si continuer avec nouvel objectif
            if not Prompt.ask("\nContinuer avec un nouvel exercice?", choices=["oui", "non"], default="oui"):
                break

        # Rapport final
        self._display_progress_report()
        console.print("\n[green]üéâ Session termin√©e![/green]")

    def _generate_similar_exercise(self, original_exercise: Exercise) -> Exercise:
        """G√©n√®re un exercice similaire au pr√©c√©dent (m√™me concept et difficult√©)"""
        if not self.llm:
            # Fallback simple - ajoute une variation √† l'exercice original
            modified_exercise = original_exercise['exercise'].replace("=", "+ 1 =") if "=" in original_exercise['exercise'] else original_exercise['exercise'] + " (variation)"
            return Exercise(
                exercise=modified_exercise,
                solution=f"Solution similaire √†: {original_exercise['solution']}",
                hints=original_exercise['hints'],
                difficulty=original_exercise['difficulty'],
                concept=original_exercise['concept']
            )

        try:
            task = Task(
                description=f"""
                Tu es un professeur de math√©matiques expert.
                G√©n√®re un NOUVEL exercice SIMILAIRE mais DIFF√âRENT √† l'exercice suivant, 
                avec la M√äME difficult√© et portant sur le M√äME concept math√©matique.

                CONTEXTE:
                - Exercice original: {original_exercise['exercise']}
                - Concept: {original_exercise['concept']}
                - Difficult√©: {original_exercise['difficulty']}
                - Solution originale: {original_exercise['solution']}

                EXIGENCES:
                1. L'exercice doit tester les m√™mes comp√©tences mais avec des valeurs/nombres diff√©rents
                2. Doit √™tre du m√™me niveau de difficult√©
                3. Doit inclure une solution compl√®te
                4. Doit fournir des indices p√©dagogiques
                5. Doit √™tre clair et pr√©cis
                """,
                expected_output="Un objet Exercise complet avec les champs: exercise, solution, hints, difficulty, concept",
                agent=self.exercise_creator,
                output_pydantic=Exercise
            )

            crew = Crew(
                agents=[self.exercise_creator], 
                tasks=[task],
                process=Process.sequential,
                verbose=False 
            )
            
            result = crew.kickoff()
            print("\nEXercice:", result['exercise'])
            print("\nconcept:", result['concept'] )
            print("\ndifficulty:", result['difficulty'])
            print("\nhints:", "\n".join(result['hints']) )
            return result
            
        except Exception as e:
            console.print(f"[red]Erreur lors de la g√©n√©ration d'exercice similaire: {str(e)}[/red]")
            # Fallback en cas d'erreur
            return self._generate_exercise()
    def monitor_student_progress(self):
        """Surveille la progression des √©tudiants"""
        from evidently.report import Report
        from evidently.metrics import (
            ColumnDriftMetric,
            DatasetDriftMetric,
            DatasetMissingValuesMetric
        )
        
        if not self.current_student or not self.current_student.learning_history:
            return

        # Convertir l'historique en DataFrame
        df = pd.DataFrame(self.current_student.learning_history)
        
        # Configurer le rapport
        report = Report(metrics=[
            ColumnDriftMetric(column_name="is_correct"),
            DatasetDriftMetric(),
            DatasetMissingValuesMetric()
        ])
        
        # G√©n√©rer le rapport
        report.run(
            reference_data=df.iloc[:len(df)//2],  # Premi√®re moiti√© comme r√©f√©rence
            current_data=df.iloc[len(df)//2:],    # Deuxi√®me moiti√© comme donn√©es courantes
        )
        
        # Sauvegarder le rapport
        if hasattr(self, 'mlflow_run') and self.mlflow_run:
            mlflow.log_dict(report.json(), "monitoring_report.json")
        
if __name__ == "__main__":
    try:
        system = MathTutoringSystem()
        system.start_learning_session()
    except Exception as e:
        console.print(f"[red]‚ùå Erreur critique: {str(e)}[/red]")
    finally:
        console.print("[blue]Merci d'avoir utilis√© notre syst√®me![/blue]")